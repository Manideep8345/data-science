{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time as T\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "path ='image_stitching/test' #''/home/mandy8345/www/video/friction/new'\n",
    "files = os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "path ='image_stitching/test' #''/home/mandy8345/www/video/friction/new'\n",
    "files = os.listdir(path)\n",
    "i = 0\n",
    "l=i\n",
    "files.sort()\n",
    "for file in files:\n",
    "    os.rename(os.path.join(path, file), os.path.join(path,'img'+str(i)+'.jpg'))\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stitched_image(img1, img2, M):\n",
    "\n",
    "    # Get width and height of input images\t\n",
    "    w1,h1 = img1.shape[:2]\n",
    "    w2,h2 = img2.shape[:2]\n",
    "\n",
    "    # Get the canvas dimesions\n",
    "    img1_dims = np.float32([ [0,0], [0,w1], [h1, w1], [h1,0] ]).reshape(-1,1,2)\n",
    "    img2_dims_temp = np.float32([ [0,0], [0,w2], [h2, w2], [h2,0] ]).reshape(-1,1,2)\n",
    "\n",
    "\n",
    "    # Get relative perspective of second image\n",
    "    img2_dims = cv2.perspectiveTransform(img2_dims_temp, M)\n",
    "\n",
    "    # Resulting dimensions\n",
    "    result_dims = np.concatenate( (img1_dims, img2_dims), axis = 0)\n",
    "\n",
    "    # Getting images together\n",
    "    # Calculate dimensions of match points\n",
    "    [x_min, y_min] = np.int32(result_dims.min(axis=0).ravel() - 0.5)\n",
    "    [x_max, y_max] = np.int32(result_dims.max(axis=0).ravel() + 0.5)\n",
    "\n",
    "    # Create output array after affine transformation \n",
    "    transform_dist = [-x_min,-y_min]\n",
    "    transform_array = np.array([[1, 0, transform_dist[0]], \n",
    "                                [0, 1, transform_dist[1]], \n",
    "                                [0,0,1]]) \n",
    "\n",
    "    # Warp images to get the resulting image\n",
    "    result_img = cv2.warpPerspective(img2, transform_array.dot(M), \n",
    "                                    (x_max-x_min, y_max-y_min))\n",
    "    result_img[transform_dist[1]:w1+transform_dist[1], \n",
    "                transform_dist[0]:h1+transform_dist[0]] = img1\n",
    "\n",
    "    # Return the result\n",
    "    return result_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find SIFT and return Homography Matrix\n",
    "def get_sift_homography(img1, img2):\n",
    "\n",
    "    # Initialize SIFT \n",
    "    sift = cv2.SIFT()\n",
    "\n",
    "    # Extract keypoints and descriptors\n",
    "    k1, d1 = sift.detectAndCompute(img1, None)\n",
    "    k2, d2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    # Bruteforce matcher on the descriptors\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(d1,d2, k=2)\n",
    "\n",
    "    # Make sure that the matches are good\n",
    "    verify_ratio = 0.8 # Source: stackoverflow\n",
    "    verified_matches = []\n",
    "    for m1,m2 in matches:\n",
    "        # Add to array only if it's a good match\n",
    "        if m1.distance < 0.8 * m2.distance:\n",
    "            verified_matches.append(m1)\n",
    "\n",
    "    # Mimnum number of matches\n",
    "    min_matches = 8\n",
    "    if len(verified_matches) > min_matches:\n",
    "\n",
    "        # Array to store matching points\n",
    "        img1_pts = []\n",
    "        img2_pts = []\n",
    "\n",
    "        # Add matching points to array\n",
    "        for match in verified_matches:\n",
    "            img1_pts.append(k1[match.queryIdx].pt)\n",
    "            img2_pts.append(k2[match.trainIdx].pt)\n",
    "        img1_pts = np.float32(img1_pts).reshape(-1,1,2)\n",
    "        img2_pts = np.float32(img2_pts).reshape(-1,1,2)\n",
    "\n",
    "        # Compute homography matrix\n",
    "        M, mask = cv2.findHomography(img1_pts, img2_pts, cv2.RANSAC, 5.0)\n",
    "        return M\n",
    "    else:\n",
    "        print 'Error: Not enough matches'\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 11 15 19 23 27 31 35 39 43 47 51 55 59 63 67 71 75 79 83 87 91 95 99 103 107 111 115 119 123 127 131 135 139 143 "
     ]
    }
   ],
   "source": [
    "# Get input set of images\n",
    "t=T.clock()\n",
    "fil=\"image_stitching/test/\"\n",
    "img1 = cv2.imread(fil+'img3.jpg')\n",
    "result= fil+'result0.jpg'\n",
    "#cv2.imshow ('Result', img1)\n",
    "#cv2.waitKey()\n",
    "i=7;j=0\n",
    "er=0\n",
    "#for i in xrange(374):\n",
    "while(i<201):\n",
    "    print i,\n",
    "    if(i!=0):\n",
    "        img1 = cv2.imread(result)\n",
    "        \"\"\"if((i+1)%100==0 and er!=i):\n",
    "            er=i;i=i-10;j+=1\n",
    "            img1 = cv2.imread(fil+'img'+str(i)+'.jpg')\n",
    "            result = fil+'result'+str(j)+'.jpg'\"\"\"\n",
    "    #img1 = cv2.imread(fil+'img'+str(i)+'.jpg')\n",
    "    img2 = cv2.imread(fil+'img'+str(i)+'.jpg')\n",
    "\n",
    "\n",
    "    # Equalize histogram\n",
    "    #img1 = equalize_histogram_color(img1)\n",
    "    #img2 = equalize_histogram_color(img2)\n",
    "\n",
    "    # Show input images\n",
    "    #input_images = np.hstack( (img1, img2) )\n",
    "    #cv2.imshow ('Input Images', input_images)\n",
    "\n",
    "    # Use SIFT to find keypoints and return homography matrix\n",
    "    M =  get_sift_homography(img1, img2)\n",
    "\n",
    "    # Stitch the images together using homography matrix\n",
    "    result_image = get_stitched_image(img2, img1, M)\n",
    "\n",
    "    # Write the result to the same directory\n",
    "    cv2.imwrite(result, result_image)\n",
    "    i+=4\n",
    "\n",
    "    # Show the resulting image\n",
    "    #cv2.imshow ('Result', result_image)\n",
    "    #cv2.waitKey()\n",
    "print 'time: ',T.clock()-t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 9\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "while(i<10):\n",
    "    print i,\n",
    "    if i==3:\n",
    "        i=8\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4416/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the keypoints to stitch the images\n",
    "def get_stitched_image(img1, img2, M):\n",
    "\n",
    "\t# Get width and height of input images\t\n",
    "\tw1,h1 = img1.shape[:2]\n",
    "\tw2,h2 = img2.shape[:2]\n",
    "\n",
    "\t# Get the canvas dimesions\n",
    "\timg1_dims = np.float32([ [0,0], [0,w1], [h1, w1], [h1,0] ]).reshape(-1,1,2)\n",
    "\timg2_dims_temp = np.float32([ [0,0], [0,w2], [h2, w2], [h2,0] ]).reshape(-1,1,2)\n",
    "\n",
    "\n",
    "\t# Get relative perspective of second image\n",
    "\timg2_dims = cv2.perspectiveTransform(img2_dims_temp, M)\n",
    "\n",
    "\t# Resulting dimensions\n",
    "\tresult_dims = np.concatenate( (img1_dims, img2_dims), axis = 0)\n",
    "\n",
    "\t# Getting images together\n",
    "\t# Calculate dimensions of match points\n",
    "\t[x_min, y_min] = np.int32(result_dims.min(axis=0).ravel() - 0.5)\n",
    "\t[x_max, y_max] = np.int32(result_dims.max(axis=0).ravel() + 0.5)\n",
    "\t\n",
    "\t# Create output array after affine transformation \n",
    "\ttransform_dist = [-x_min,-y_min]\n",
    "\ttransform_array = np.array([[1, 0, transform_dist[0]], \n",
    "\t\t\t\t\t\t\t\t[0, 1, transform_dist[1]], \n",
    "\t\t\t\t\t\t\t\t[0,0,1]]) \n",
    "\n",
    "\t# Warp images to get the resulting image\n",
    "\tresult_img = cv2.warpPerspective(img2, transform_array.dot(M), \n",
    "\t\t\t\t\t\t\t\t\t(x_max-x_min, y_max-y_min))\n",
    "\tresult_img[transform_dist[1]:w1+transform_dist[1], \n",
    "\t\t\t\ttransform_dist[0]:h1+transform_dist[0]] = img1\n",
    "\n",
    "\t# Return the result\n",
    "\treturn result_img\n",
    "\n",
    "# Find SIFT and return Homography Matrix\n",
    "def get_sift_homography(img1, img2):\n",
    "\n",
    "\t# Initialize SIFT \n",
    "\tsift = cv2.SIFT()\n",
    "\n",
    "\t# Extract keypoints and descriptors\n",
    "\tk1, d1 = sift.detectAndCompute(img1, None)\n",
    "\tk2, d2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "\t# Bruteforce matcher on the descriptors\n",
    "\tbf = cv2.BFMatcher()\n",
    "\tmatches = bf.knnMatch(d1,d2, k=2)\n",
    "\n",
    "\t# Make sure that the matches are good\n",
    "\tverify_ratio = 0.8 # Source: stackoverflow\n",
    "\tverified_matches = []\n",
    "\tfor m1,m2 in matches:\n",
    "\t\t# Add to array only if it's a good match\n",
    "\t\tif m1.distance < 0.8 * m2.distance:\n",
    "\t\t\tverified_matches.append(m1)\n",
    "\n",
    "\t# Mimnum number of matches\n",
    "\tmin_matches = 8\n",
    "\tif len(verified_matches) > min_matches:\n",
    "\t\t\n",
    "\t\t# Array to store matching points\n",
    "\t\timg1_pts = []\n",
    "\t\timg2_pts = []\n",
    "\n",
    "\t\t# Add matching points to array\n",
    "\t\tfor match in verified_matches:\n",
    "\t\t\timg1_pts.append(k1[match.queryIdx].pt)\n",
    "\t\t\timg2_pts.append(k2[match.trainIdx].pt)\n",
    "\t\timg1_pts = np.float32(img1_pts).reshape(-1,1,2)\n",
    "\t\timg2_pts = np.float32(img2_pts).reshape(-1,1,2)\n",
    "\t\t\n",
    "\t\t# Compute homography matrix\n",
    "\t\tM, mask = cv2.findHomography(img1_pts, img2_pts, cv2.RANSAC, 5.0)\n",
    "\t\treturn M\n",
    "\telse:\n",
    "\t\tprint 'Error: Not enough matches'\n",
    "\t\texit()\n",
    "\n",
    "# Equalize Histogram of Color Images\n",
    "def equalize_histogram_color(img):\n",
    "\timg_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "\timg_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n",
    "\timg = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)\n",
    "\treturn img\n",
    "\n",
    "# Main function definition\n",
    "def main():\n",
    "\t\n",
    "\t# Get input set of images\n",
    "\timg1 = cv2.imread(sys.argv[1])\n",
    "\timg2 = cv2.imread(sys.argv[2])\n",
    "\n",
    "\t# Equalize histogram\n",
    "\timg1 = equalize_histogram_color(img1)\n",
    "\timg2 = equalize_histogram_color(img2)\n",
    "\n",
    "\t# Show input images\n",
    "\t#input_images = np.hstack( (img1, img2) )\n",
    "\t#cv2.imshow ('Input Images', input_images)\n",
    "\n",
    "\t# Use SIFT to find keypoints and return homography matrix\n",
    "\tM =  get_sift_homography(img1, img2)\n",
    "\n",
    "\t# Stitch the images together using homography matrix\n",
    "\tresult_image = get_stitched_image(img2, img1, M)\n",
    "\n",
    "\t# Write the result to the same directory\n",
    "\tresult_image_name = 'results/result_'+sys.argv[1]\n",
    "\tcv2.imwrite(result_image_name, result_image)\n",
    "\n",
    "\t# Show the resulting image\n",
    "\tcv2.imshow ('Result', result_image)\n",
    "\tcv2.waitKey()\n",
    "\n",
    "# Call main function\n",
    "if __name__=='__main__':\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv2_match(im1, im2):\n",
    "    #mysift = SIFT()\n",
    "    sift = cv2.SIFT()\n",
    "    bf = cv2.BFMatcher()\n",
    "\n",
    "\n",
    "    kp1, dp1 = sift.detectAndCompute(im1, None)\n",
    "    kp2, dp2 = sift.detectAndCompute(im2, None)\n",
    "    matches_ = bf.knnMatch(dp1, dp2, k=2)\n",
    "\n",
    "    print(len(matches_))\n",
    "    good = []\n",
    "    for m, n in matches_:\n",
    "        if m.distance < 0.90 * n.distance:\n",
    "            good.append(m)\n",
    "    print(len(good))\n",
    "\n",
    "    pos1 = [(int(kp.pt[1]), int(kp.pt[0])) for kp in kp1]\n",
    "    pos2 = [(int(kp.pt[1]), int(kp.pt[0])) for kp in kp2]\n",
    "    matches = [(m.queryIdx, m.trainIdx, 0.15) for m in good]\n",
    "\n",
    "    cv2.imwrite(\"cvkp1.jpg\", cv2.drawKeypoints(im1, kp1, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS))\n",
    "    cv2.imwrite(\"cvkp2.jpg\", cv2.drawKeypoints(im2, kp2, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS))\n",
    "    #cv2.drawMatches(im, pos1, imm, pos2, matches, 'ckmatch.jpg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3613\n",
      "1543\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'drawMatches'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-39b0d815883d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mim1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfil\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"img3.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mim2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfil\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"img4.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcv2_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-ba75d8499f5a>\u001b[0m in \u001b[0;36mcv2_match\u001b[0;34m(im1, im2)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cvkp1.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrawKeypoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cvkp2.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrawKeypoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrawMatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ckmatch.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'drawMatches'"
     ]
    }
   ],
   "source": [
    "fil=\"image_stitching/test/\"\n",
    "im1=cv2.imread(fil+\"img3.jpg\")\n",
    "im2=cv2.imread(fil+\"img4.jpg\")\n",
    "cv2_match(im1, im2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
