{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Layer 1.\n",
    "filter_size1 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters1 = 16         # There are 16 of these filters.\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters2 = 36         # There are 36 of these filters.\n",
    "\n",
    "#convolutional Layer 3\n",
    "filter_size3 = 5\n",
    "num_filter3 = 36\n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size1 = 300             # Number of neurons in fully-connected layer1.\n",
    "fc_size2 = 300\n",
    "\n",
    "# seed to make debugging easy\n",
    "seed =165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('data/MNIST/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_batch=data.train.images\n",
    "#y_true_batch=data.train.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch, y_true_batch = data.train.next_batch(1060000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test,y_test_tru=data.test.next_batch(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know that MNIST images are 28 pixels in each dimension.\n",
    "img_size = 28\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = img_size * img_size\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "# Number of colour channels for the images: 1 channel for gray-scale.\n",
    "num_channels = 1\n",
    "\n",
    "# Number of classes, one class for each of 10 digits.\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape,seed=seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_biases(length):\n",
    "    return tf.Variable(tf.random_normal([length],seed=seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_conv_layer(input,              # The previous layer.\n",
    "                   num_input_channels, # Num. channels in prev. layer.\n",
    "                   filter_size,        # Width and height of each filter.\n",
    "                   num_filters,        # Number of filters.\n",
    "                   use_pooling=True):  # Use 2x2 max-pooling.\n",
    "\n",
    "    # Shape of the filter-weights for the convolution.\n",
    "    # This format is determined by the TensorFlow API.\n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "\n",
    "    # Create new weights aka. filters with the given shape.\n",
    "    weights = new_weights(shape=shape)\n",
    "\n",
    "    # Create new biases, one for each filter.\n",
    "    biases = new_biases(length=num_filters)\n",
    "\n",
    "    # Create the TensorFlow operation for convolution.\n",
    "    # Note the strides are set to 1 in all dimensions.\n",
    "    # The first and last stride must always be 1,\n",
    "    # because the first is for the image-number and\n",
    "    # the last is for the input-channel.\n",
    "    # But e.g. strides=[1, 2, 2, 1] would mean that the filter\n",
    "    # is moved 2 pixels across the x- and y-axis of the image.\n",
    "    # The padding is set to 'SAME' which means the input image\n",
    "    # is padded with zeroes so the size of the output is the same.\n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                         filter=weights,\n",
    "                         strides=[1, 1, 1, 1],\n",
    "                         padding='SAME')\n",
    "\n",
    "    # Add the biases to the results of the convolution.\n",
    "    # A bias-value is added to each filter-channel.\n",
    "    layer += biases\n",
    "\n",
    "    # Use pooling to down-sample the image resolution?\n",
    "    if use_pooling:\n",
    "        # This is 2x2 max-pooling, which means that we\n",
    "        # consider 2x2 windows and select the largest value\n",
    "        # in each window. Then we move 2 pixels to the next window.\n",
    "        layer = tf.nn.max_pool(value=layer,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME')\n",
    "\n",
    "    # Rectified Linear Unit (ReLU).\n",
    "    # It calculates max(x, 0) for each input pixel x.\n",
    "    # This adds some non-linearity to the formula and allows us\n",
    "    # to learn more complicated functions.\n",
    "    layer = tf.nn.relu(layer)\n",
    "\n",
    "    # Note that ReLU is normally executed before the pooling,\n",
    "    # but since relu(max_pool(x)) == max_pool(relu(x)) we can\n",
    "    # save 75% of the relu-operations by max-pooling first.\n",
    "\n",
    "    # We return both the resulting layer and the filter-weights\n",
    "    # because we will plot the weights later.\n",
    "    return layer, weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_layer(layer):\n",
    "    # Get the shape of the input layer.\n",
    "    layer_shape = layer.get_shape()\n",
    "\n",
    "    # The shape of the input layer is assumed to be:\n",
    "    # layer_shape == [num_images, img_height, img_width, num_channels]\n",
    "\n",
    "    # The number of features is: img_height * img_width * num_channels\n",
    "    # We can use a function from TensorFlow to calculate this.\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    \n",
    "    # Reshape the layer to [num_images, num_features].\n",
    "    # Note that we just set the size of the second dimension\n",
    "    # to num_features and the size of the first dimension to -1\n",
    "    # which means the size in that dimension is calculated\n",
    "    # so the total size of the tensor is unchanged from the reshaping.\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "\n",
    "    # The shape of the flattened layer is now:\n",
    "    # [num_images, img_height * img_width * num_channels]\n",
    "\n",
    "    # Return both the flattened layer and the number of features.\n",
    "    return layer_flat,num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_fc_layer(input,          # The previous layer.\n",
    "                 num_inputs,     # Num. inputs from prev. layer.\n",
    "                 num_outputs,    # Num. outputs.\n",
    "                 use_relu=True,\n",
    "                dropout=False,\n",
    "                kep_prob=1): # Use Rectified Linear Unit (ReLU)?\n",
    "\n",
    "    # Create new weights and biases.\n",
    "    weights = new_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = new_biases(length=num_outputs)\n",
    "\n",
    "    # Calculate the layer as the matrix multiplication of\n",
    "    # the input and weights, and then add the bias-values.\n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "\n",
    "    # Use ReLU?\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "    if dropout:\n",
    "        layer = tf.nn.dropout(layer,kep_prob)\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "kee_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_cls = tf.argmax(y_true, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_conv1, weights_conv1 = new_conv_layer(input=x_image,num_input_channels=num_channels,filter_size=filter_size1,num_filters=num_filters1,use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_conv2, weights_conv2 = new_conv_layer(input=layer_conv1,num_input_channels=num_filters1,filter_size=filter_size2,num_filters=num_filters2,use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_flat, num_features = flatten_layer(layer_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                         num_inputs=num_features,\n",
    "                         num_outputs=fc_size1,\n",
    "                         use_relu=True,\n",
    "                         kep_prob=kee_prob,\n",
    "                         dropout=True)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc2 = new_fc_layer(input=layer_fc1,\n",
    "                         num_inputs=fc_size1,\n",
    "                         num_outputs=fc_size2,\n",
    "                         use_relu=True,\n",
    "                         kep_prob=kee_prob,\n",
    "                         dropout=True)\n",
    "                         \n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc3 = new_fc_layer(input=layer_fc2,\n",
    "                         num_inputs=fc_size2,\n",
    "                         num_outputs=num_classes,\n",
    "                         use_relu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(layer_fc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cls = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=layer_fc3,\n",
    "                                                        labels=y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pat='temp/CNN/mnist_cnn.ckpt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 1 Batch: 1000 Cost: 13.1813143978\n",
      "Round: 1 Batch: 2000 Cost: 22.6306515198\n",
      "Round: 1 Batch: 3000 Cost: 20.4824664726\n",
      "Round: 1 Batch: 4000 Cost: 16.1547400627\n",
      "Round: 1 Batch: 5000 Cost: 18.4467620544\n",
      "Round: 1 Batch: 6000 Cost: 15.6925638542\n",
      "Round: 1 Batch: 7000 Cost: 18.6268839396\n",
      "Round: 1 Batch: 8000 Cost: 22.3060575909\n",
      "Round: 1 Batch: 9000 Cost: 17.1608014699\n",
      "Round: 1 Batch: 10000 Cost: 19.1481070175\n",
      "Round: 1 Batch: 11000 Cost: 17.2374863567\n",
      "Round: 2 Batch: 1000 Cost: 16.2271739988\n",
      "Round: 2 Batch: 2000 Cost: 16.825999427\n",
      "Round: 2 Batch: 3000 Cost: 17.2356368732\n",
      "Round: 2 Batch: 4000 Cost: 18.1712877998\n",
      "Round: 2 Batch: 5000 Cost: 23.8690185223\n",
      "Round: 2 Batch: 6000 Cost: 14.0931378925\n",
      "Round: 2 Batch: 7000 Cost: 21.4331400897\n",
      "Round: 2 Batch: 8000 Cost: 18.0033720546\n",
      "Round: 2 Batch: 9000 Cost: 16.9109003363\n",
      "Round: 2 Batch: 10000 Cost: 8.49187057588\n",
      "Round: 2 Batch: 11000 Cost: 20.0719099445\n",
      "Round: 3 Batch: 1000 Cost: 17.3217916958\n",
      "Round: 3 Batch: 2000 Cost: 19.622526675\n",
      "Round: 3 Batch: 3000 Cost: 15.3247084312\n",
      "Round: 3 Batch: 4000 Cost: 17.4770394162\n",
      "Round: 3 Batch: 5000 Cost: 17.2384642334\n",
      "Round: 3 Batch: 6000 Cost: 15.2540340762\n",
      "Round: 3 Batch: 7000 Cost: 11.6688389075\n",
      "Round: 3 Batch: 8000 Cost: 14.3614068184\n",
      "Round: 3 Batch: 9000 Cost: 14.9024682045\n",
      "Round: 3 Batch: 10000 Cost: 15.1295102262\n",
      "Round: 3 Batch: 11000 Cost: 8.58100428446\n",
      "\n",
      "Time took 2616.937791\n"
     ]
    }
   ],
   "source": [
    "t=time.clock()\n",
    "c_sum=0\n",
    "for ju in xrange(3):\n",
    "    for i in xrange(11000):\n",
    "        huyt=x_batch[i*10:(i+1)*10-1]#sedwe[:,0:1],sedwe[:,1:]\n",
    "        sdws=y_true_batch[i*10:(i+1)*10-1]\n",
    "        _, c = session.run([optimizer,cost],feed_dict={x:huyt,y_true:sdws,kee_prob:0.8})\n",
    "        c_sum+=c\n",
    "        if (i+1)%1000==0:\n",
    "            print \"Round:\",ju+1,\"Batch:\", i+1,\"Cost:\",c_sum/1000.0\n",
    "            c_sum=0\n",
    "print \"\\nTime took\",time.clock()-t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "Time took 88.687533 \n",
      "Accuracy: 98.34 %\n"
     ]
    }
   ],
   "source": [
    "t=time.clock()\n",
    "j=0\n",
    "print 67\n",
    "kd_no=[]\n",
    "#predict = (, 1)\n",
    "#test_x=np.array(test.loc[:])\n",
    "for i in xrange(20000):\n",
    "    pred = session.run(y_pred_cls,{x:x_test[i:i+1],kee_prob:1.0})\n",
    "    if pred == np.argmax(y_test_tru[i]):\n",
    "        j+=1\n",
    "    else:\n",
    "        kd_no.append(i)\n",
    "        \n",
    "\n",
    "print \"Time took\",time.clock()-t,'\\nAccuracy:',j*100.0/20000,\"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "Time took 106.705189 \n",
      "Accuracy: 98.26 %\n"
     ]
    }
   ],
   "source": [
    "t=time.clock()\n",
    "j=0\n",
    "print 67\n",
    "kd_no=[]\n",
    "#predict = (, 1)\n",
    "#test_x=np.array(test.loc[:])\n",
    "for i in xrange(20000):\n",
    "    pred = session.run(y_pred_cls,{x:x_test[i:i+1],kee_prob:1.0})\n",
    "    if pred == np.argmax(y_test_tru[i]):\n",
    "        j+=1\n",
    "    else:\n",
    "        kd_no.append(i)\n",
    "        \n",
    "\n",
    "print \"Time took\",time.clock()-t,'\\nAccuracy:',j*100.0/20000,\"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19652, 348)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j,20000-j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0] \n",
      "true: 0\n",
      "0.007801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2a1a741ad0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYwPhxHc4NhBOfIdjA/H/AR4xguINh+AIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2a218b6cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t=time.clock()\n",
    "shap=[28,28]\n",
    "#i=kd_no[280]\n",
    "i=25\n",
    "print 'pred:',session.run(y_pred_cls,{x:x_test[i:i+1],kee_prob:1.0}),'\\ntrue:',np.argmax(y_test_tru[i])\n",
    "print time.clock()-t\n",
    "plt.imshow(x_test[i].reshape(shap),cmap='binary')\n",
    "#print time.clock()-t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temp/CNN/mnist_cnn.ckpt'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(sess=session,save_path=save_pat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## restore the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from temp/CNN/mnist_cnn.ckpt\n"
     ]
    }
   ],
   "source": [
    "saver.restore(sess=session,save_path=save_pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_in_checkpoint = tf.train.list_variables(save_pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Variable', [5, 5, 1, 16]),\n",
       " ('Variable/Adam', [5, 5, 1, 16]),\n",
       " ('Variable/Adam_1', [5, 5, 1, 16]),\n",
       " ('Variable_1', [16]),\n",
       " ('Variable_1/Adam', [16]),\n",
       " ('Variable_1/Adam_1', [16]),\n",
       " ('Variable_2', [5, 5, 16, 36]),\n",
       " ('Variable_2/Adam', [5, 5, 16, 36]),\n",
       " ('Variable_2/Adam_1', [5, 5, 16, 36]),\n",
       " ('Variable_3', [36]),\n",
       " ('Variable_3/Adam', [36]),\n",
       " ('Variable_3/Adam_1', [36]),\n",
       " ('Variable_4', [1764, 300]),\n",
       " ('Variable_4/Adam', [1764, 300]),\n",
       " ('Variable_4/Adam_1', [1764, 300]),\n",
       " ('Variable_5', [300]),\n",
       " ('Variable_5/Adam', [300]),\n",
       " ('Variable_5/Adam_1', [300]),\n",
       " ('Variable_6', [300, 300]),\n",
       " ('Variable_6/Adam', [300, 300]),\n",
       " ('Variable_6/Adam_1', [300, 300]),\n",
       " ('Variable_7', [300]),\n",
       " ('Variable_7/Adam', [300]),\n",
       " ('Variable_7/Adam_1', [300]),\n",
       " ('Variable_8', [300, 10]),\n",
       " ('Variable_8/Adam', [300, 10]),\n",
       " ('Variable_8/Adam_1', [300, 10]),\n",
       " ('Variable_9', [10]),\n",
       " ('Variable_9/Adam', [10]),\n",
       " ('Variable_9/Adam_1', [10]),\n",
       " ('beta1_power', []),\n",
       " ('beta2_power', [])]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_in_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
